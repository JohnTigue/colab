{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_vm_config_info.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeC-AbggYh6s",
        "colab_type": "text"
      },
      "source": [
        "# DEAD CODE\n",
        "\n",
        "This is now dead code. It moved repos from johntigue/colab-utils to reconstrue/dev_on_colab as [colab_vm_config.ipynb](https://github.com/reconstrue/dev_on_colab/blob/master/platform/colab_vm_config.ipynb).\n",
        "\n",
        "# Colab VM configuration information\n",
        "\n",
        "This notebook is intended simply for dumping status information from a Colab runtime (kernel, VM, whatever)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3SbviHli8Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Various installs of packages imported by colab_vm_config_info.ipynb\n",
        "!pip install humanize\n",
        "!pip install gputil\n",
        "!pip install psutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv-SjRT3KsUT",
        "colab_type": "text"
      },
      "source": [
        "## Python environment stats\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhQ_f7n1K_eK",
        "colab_type": "code",
        "outputId": "608c5215-7c74-41e4-8b11-3127142108a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# What version of Python is in effect?\n",
        "\n",
        "import platform\n",
        "\n",
        "a_message = \"Python runtime version: \" + platform.python_version() \n",
        "print(a_message)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python runtime version: 3.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV6LDzpn0BgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What packages are installed for the detected running version of Python?\n",
        "import platform\n",
        "\n",
        "python_major_version = int(platform.python_version_tuple()[0])\n",
        "print(python_major_version)\n",
        "\n",
        "if python_major_version == 3:\n",
        "  print(\"Python 3.6 dist-packages\")\n",
        "  !ls /usr/local/lib/python3.6/dist-packages\n",
        "else: \n",
        "  # Python 2 it is...\n",
        "  print(\"Python 2.7 dist-packages\")\n",
        "  !ls /usr/local/lib/python2.7/dist-packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMWkr5BRhJwi",
        "colab_type": "text"
      },
      "source": [
        "## Jupyter stats\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_XbzwHbhOCs",
        "colab_type": "code",
        "outputId": "c00008ce-3ab7-428e-968f-cf6b9e05df9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!jupyter-kernelspec list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available kernels:\n",
            "  ir         /usr/local/share/jupyter/kernels/ir\n",
            "  python2    /usr/local/share/jupyter/kernels/python2\n",
            "  python3    /usr/local/share/jupyter/kernels/python3\n",
            "  swift      /usr/local/share/jupyter/kernels/swift\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbfElYWtEGX",
        "colab_type": "text"
      },
      "source": [
        "## Check VM Uptime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUVolHFGAELj",
        "colab_type": "text"
      },
      "source": [
        "Supposedly these Colab kernel (runtimes, VMs, whatever) are thrown away after a max of 12 hours. In the results of `uptime` is the time-of-day (formatted `HH:MM:SS`) followed by ` up: ` followed by how long the VM has been up (formatted as `XX min`, or after an hour as `H:MM`).\n",
        "\n",
        "Note, the 12 hour lifetime cap is the max but less can happen it seems. Seemingly, [this issue is not well defined by google](https://stackoverflow.com/questions/55050988/can-i-run-a-google-colab-free-edition-script-and-then-shutdown-my-computer).\n",
        "\n",
        "Furthermore, VM max lifetime is different than the constant runtime disconnects. These seem to happen on the order of 60 to 90 minutes. Supposedly keeping a code cell running can keep the connection from disconnect timeouts. Note though that editing text cells does not reset the timeout clock."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw4ETaUArMJK",
        "colab_type": "code",
        "outputId": "ff66a2f4-3e1f-4de2-b736-492b822c9462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# How long has this VM been up? \n",
        "!uptime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 08:25:49 up  1:00,  0 users,  load average: 0.12, 0.10, 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xey9UaJVCyqR",
        "colab_type": "text"
      },
      "source": [
        "## Reset VM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvI-zBE8dwud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset VM\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rim_Xy3h--W",
        "colab_type": "text"
      },
      "source": [
        "## CPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd9OM-gSYdaE",
        "colab_type": "code",
        "outputId": "d1b766bb-954f-4ef6-aa93-3cdc6f07b60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# How many CPUs does this machine have?\n",
        "!lscpu | grep \"^CPU(s):\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU(s):              2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7eY-Lq9dFBy",
        "colab_type": "code",
        "outputId": "5c994b17-b598-4d8b-a442-7b2dd642fa3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "# More details on the CPU(s):\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhb8bXJIZU9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RAM\n",
        "!cat /proc/meminfo | head -n3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeSy0EpOigS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RAM info humanized\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl8OjjKSEp_4",
        "colab_type": "text"
      },
      "source": [
        "## File System\n",
        "\n",
        "As with AWS Lambda, there are intentionally few switches for selecting VM options. Memory and CPU are provided as matching packages, not independently configurable.\n",
        "\n",
        "So, depending on what you ask for in terms of compute (CPU, GPU, [TPU](https://colab.research.google.com/notebooks/tpu.ipynb)) you get more or less file system memory [[*](https://stackoverflow.com/a/55890688)]. Note: for all compute options, the OS files initialize to consuming about 25MB of the file system before you are dropped into the kernel. \n",
        "\n",
        "On 2019-05-19, the following tests gave these results:\n",
        "\n",
        "Processor | FS Free GB | FS Total GB \n",
        "--|--|--\n",
        "CPU | 24 | 49\n",
        "GPU | 318 | 359\n",
        "TPU | 26| 49\n",
        "\n",
        "The low FS size for the TPU is probably because for the TPU case, those (the actually TPU boards) are separate machines while for GPUs those  are a part of the machine the notebook is running on. So, for the CPU and the TPU options, Google is probably providing the same VM, ergo the file systems are essentially the same size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XITlujDERuVd",
        "colab_type": "code",
        "outputId": "0d595737-505a-4d7c-abe8-6ce3d9b20058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!df -h ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          49G   23G   24G  49% /\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeD7R1g_iFLO",
        "colab_type": "text"
      },
      "source": [
        "## GPU Information\n",
        "\n",
        "In the following code cell, if the result is:\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver.\n",
        "```\n",
        "Then that means the Runtime is not set to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAPlyttC-jWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d15e97f-4953-4c21-d453-eece31d621c9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-tpXTLhbsg7",
        "colab_type": "code",
        "outputId": "4982928b-5bf4-49c8-e4fa-8f0c9eda2544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# What GPU is currently config'd for use?\n",
        "\n",
        "# https://colab.research.google.com/notebooks/gpu.ipynb\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\"GPU detected: NONE\")\n",
        "else:\n",
        "  print('GPU detected: {}'.format(device_name))\n",
        "\n",
        "# TODO: Another way?\n",
        "#from tensorflow.python.client import device_lib\n",
        "#device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU detected: NONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnpoONR1hBEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Memory in GPU\n",
        "import GPUtil as GPU\n",
        "\n",
        "gpus = GPU.getGPUs()\n",
        "\n",
        "if len(gpus) > 0:\n",
        "  gpu = gpus[0]\n",
        "  print(\"GPU RAM:\\n Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "else:\n",
        "  print(\"GPU detected: NONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc4jEhFyZDRi",
        "colab_type": "code",
        "outputId": "17b8bdfe-fc59-409d-ebd4-5095eed316c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!nvcc --version\n",
        "!conda install tsnecuda cuda100 -c cannylab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n",
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5t8eFMPaJdc",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "* [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "* [GPU stats code](https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available)\n",
        "* [TensorFlow with GPU](https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=3IEVK-KFxi5Z)"
      ]
    }
  ]
}