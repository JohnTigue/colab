{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rapids_on_colab_probing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD",
        "colab_type": "text"
      },
      "source": [
        "# JFT metanotes\n",
        "2019-06-21, starting from https://rapids.ai/ clicked through to [Go to example notebook](https://colab.research.google.com/drive/1XTKHiIcvyL5nuldx0HSL_dUa8yopzy_Y#forceEdit=true&offline=true&sandboxMode=true)\n",
        "\n",
        "\n",
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab_type": "code",
        "outputId": "2ea00f17-f02c-4eee-cce2-497f64af83fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 21 08:22:44 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8Wv2K0uDfx",
        "colab_type": "code",
        "outputId": "7f59be11-e00d-410f-e75c-d97e51436f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "if device_name != b'Tesla T4':\n",
        "  raise Exception(\"\"\"\n",
        "    Unfortunately this instance does not have a T4 GPU.\n",
        "    \n",
        "    Please make sure you've configured Colab to request a GPU instance type.\n",
        "    \n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\n",
        "\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\n",
        "  \"\"\")\n",
        "else:\n",
        "  print('Woo! You got the right kind of GPU!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Woo! You got the right kind of GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtNdk7PSafKP",
        "colab_type": "text"
      },
      "source": [
        "#Setup:\n",
        "\n",
        "1. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n",
        "2. Install RAPIDS libraries\n",
        "3. Set necessary environment variables\n",
        "4. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jdXBRiDSzj",
        "colab_type": "code",
        "outputId": "614e26cc-12b4-4c2c-d664-768c8b6e5172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2033
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "# intall miniconda\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# install RAPIDS packages\n",
        "!conda install -q -y --prefix /usr/local -c conda-forge \\\n",
        "  -c rapidsai-nightly/label/cuda10.0 -c nvidia/label/cuda10.0 \\\n",
        "  cudf cuml\n",
        "\n",
        "# set environment vars\n",
        "import sys, os, shutil\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "# copy .so files to current working dir\n",
        "for fn in ['libcudf.so', 'librmm.so']:\n",
        "  shutil.copy('/usr/local/lib/'+fn, os.getcwd())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-21 08:26:41--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - cudf\n",
            "    - cuml\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudf-0.8.0a1               |        py36_1182         3.2 MB  rapidsai-nightly/label/cuda10.0\n",
            "    libcudf-0.8.0a1            |    cuda10.0_1182        16.8 MB  rapidsai-nightly/label/cuda10.0\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        20.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    arrow-cpp:       0.12.1-py36h0e61e49_0     conda-forge                    \n",
            "    boost-cpp:       1.68.0-h11c811c_1000      conda-forge                    \n",
            "    bzip2:           1.0.6-h14c3975_1002       conda-forge                    \n",
            "    cudatoolkit:     10.0.130-0                                               \n",
            "    cudf:            0.8.0a1-py36_1182         rapidsai-nightly/label/cuda10.0\n",
            "    cuml:            0.8.0a-cuda10.0_py36_1456 rapidsai-nightly/label/cuda10.0\n",
            "    cython:          0.29.10-py36he1b5a44_0    conda-forge                    \n",
            "    icu:             58.2-hf484d3e_1000        conda-forge                    \n",
            "    libblas:         3.8.0-7_openblas          conda-forge                    \n",
            "    libcblas:        3.8.0-7_openblas          conda-forge                    \n",
            "    libcudf:         0.8.0a1-cuda10.0_1182     rapidsai-nightly/label/cuda10.0\n",
            "    libcuml:         0.8.0a-cuda10.0_1456      rapidsai-nightly/label/cuda10.0\n",
            "    libcumlmg:       0.0.0.dev0-cuda10.0_373   nvidia/label/cuda10.0          \n",
            "    libgfortran:     3.0.0-1                   conda-forge                    \n",
            "    liblapack:       3.8.0-7_openblas          conda-forge                    \n",
            "    libnvstrings:    0.8.0a-cuda10.0_126       rapidsai-nightly/label/cuda10.0\n",
            "    libprotobuf:     3.6.1-hdbcaa40_1001       conda-forge                    \n",
            "    librmm:          0.8.0a-cuda10.0_40        rapidsai-nightly/label/cuda10.0\n",
            "    llvmlite:        0.28.0-py36hdbcaa40_0     conda-forge                    \n",
            "    numba:           0.43.1-py36hf2d7682_0     conda-forge                    \n",
            "    numpy:           1.16.4-py36h95a1406_0     conda-forge                    \n",
            "    nvstrings:       0.8.0a-py36_126           rapidsai-nightly/label/cuda10.0\n",
            "    openblas:        0.3.5-ha44fe06_0          conda-forge                    \n",
            "    pandas:          0.24.2-py36hb3f55d8_0     conda-forge                    \n",
            "    parquet-cpp:     1.5.1-4                   conda-forge                    \n",
            "    pyarrow:         0.12.1-py36hbbcf98d_0     conda-forge                    \n",
            "    python-dateutil: 2.8.0-py_0                conda-forge                    \n",
            "    pytz:            2019.1-py_0               conda-forge                    \n",
            "    rmm:             0.8.0a-py36_40            rapidsai-nightly/label/cuda10.0\n",
            "    thrift-cpp:      0.12.0-h0a07b25_1002      conda-forge                    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates: 2018.03.07-0                                              --> 2019.6.16-hecc5488_0 conda-forge\n",
            "    certifi:         2018.4.16-py36_0                                          --> 2019.6.16-py36_0     conda-forge\n",
            "    conda:           4.5.4-py36_0                                              --> 4.6.14-py36_0        conda-forge\n",
            "    cryptography:    2.2.2-py36h14c3975_0                                      --> 2.7-py36h72c5cf5_0   conda-forge\n",
            "    libgcc-ng:       7.2.0-hdf63c60_3                                          --> 9.1.0-hdf63c60_0                \n",
            "    libstdcxx-ng:    7.2.0-hdf63c60_3                                          --> 9.1.0-hdf63c60_0                \n",
            "    openssl:         1.0.2o-h20670df_0                                         --> 1.1.1b-h14c3975_1    conda-forge\n",
            "    python:          3.6.5-hc3d631a_2                                          --> 3.6.7-h381d211_1004  conda-forge\n",
            "    sqlite:          3.23.1-he433501_0                                         --> 3.28.0-h8b20d00_0    conda-forge\n",
            "    tk:              8.6.7-hc745277_3                                          --> 8.6.9-hed695b0_1002  conda-forge\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "CPU times: user 433 ms, sys: 143 ms, total: 576 ms\n",
            "Wall time: 1min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oOCJ4NYMjY7",
        "colab_type": "text"
      },
      "source": [
        "# cuDF and cuML Examples #\n",
        "\n",
        "Now you can run code! \n",
        "\n",
        "What follows are basic examples where all processing takes place on the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V38dg-oUJtEO",
        "colab_type": "text"
      },
      "source": [
        "#[cuDF](https://github.com/rapidsai/cudf)#\n",
        "\n",
        "Load a dataset into a GPU memory resident DataFrame and perform a basic calculation.\n",
        "\n",
        "Everything from CSV parsing to calculating tip percentage and computing a grouped average is done on the GPU.\n",
        "\n",
        "_Note_: You must import nvstrings and nvcategory before cudf, else you'll get errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qeuEi3MMWKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "8009bd3e-def8-4c44-a5cd-40e2bb3ed4da"
      },
      "source": [
        "!pwd\n",
        "#!ls -l\n",
        "!ls -l sample_data\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 55504\n",
            "-r-xr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jun 18 16:14 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jun 18 16:14 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jun 18 16:14 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jun 18 16:14 mnist_train_small.csv\n",
            "-r-xr-xr-x 1 root root      930 Jan  1  2000 README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwaJSKuswsNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nvstrings, nvcategory, cudf\n",
        "import io, requests\n",
        "\n",
        "# download CSV file from GitHub\n",
        "#pre-jft: url=\"https://github.com/plotly/datasets/raw/master/tips.csv\"\n",
        "#\n",
        "# JFT:\n",
        "#   Seemingly a well known data set:\n",
        "#   https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/frozen_pbmc_donor_b\n",
        "#   17MB gene/cell matrix (filtered)\n",
        "\n",
        "import urllib.request as ureq\n",
        "url = \"http://cf.10xgenomics.com/samples/cell-exp/1.1.0/frozen_pbmc_donor_b/frozen_pbmc_donor_b_filtered_gene_bc_matrices.tar.gz\"\n",
        "fname=\"frozen_pbmc_donor_b_filtered_gene_bc_matrices.tar.gz\"\n",
        "ureq.urlretrieve(url, fname)\n",
        "#content = requests.get(url).content.decode('utf-8')\n",
        "\n",
        "import tarfile\n",
        "if (fname.endswith(\"tar.gz\")):\n",
        "    tar = tarfile.open(fname, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2LnUc2VOeyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f343b80-748f-4450-c44e-6a859292c706"
      },
      "source": [
        "#!ls\n",
        "!ls filtered_matrices_mex/hg19"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "barcodes.tsv  genes.tsv  matrix.mtx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ess7820fLo5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "05b4e2ae-805e-4af4-8728-0ce5a2c1f06f"
      },
      "source": [
        "# read CSV from memory\n",
        "tips_df = cudf.read_csv(io.StringIO(content))\n",
        "tips_df['tip_percentage'] = tips_df['tip']/tips_df['total_bill']*100\n",
        "\n",
        "# display average tip by dining party size\n",
        "print(tips_df.groupby('size').tip_percentage.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size\n",
            "1    21.729201548727808\n",
            "2     16.57191917348289\n",
            "3    15.215685473711831\n",
            "4    14.594900639351334\n",
            "5    14.149548965142023\n",
            "6    15.622920072028379\n",
            "Name: tip_percentage, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul3UZJdUJqlT",
        "colab_type": "text"
      },
      "source": [
        "#[cuML](https://github.com/rapidsai/cuml)#\n",
        "\n",
        "This snippet loads a \n",
        "\n",
        "As above, all calculations are performed on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCE8WhO3HpL_",
        "colab_type": "code",
        "outputId": "cb5a0ecf-7902-4c9a-8da3-d00356542f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import cuml\n",
        "\n",
        "# Create and populate a GPU DataFrame\n",
        "df_float = cudf.DataFrame()\n",
        "df_float['0'] = [1.0, 2.0, 5.0]\n",
        "df_float['1'] = [4.0, 2.0, 1.0]\n",
        "df_float['2'] = [4.0, 2.0, 1.0]\n",
        "\n",
        "# Setup and fit clusters\n",
        "dbscan_float = cuml.DBSCAN(eps=1.0, min_samples=1)\n",
        "dbscan_float.fit(df_float)\n",
        "\n",
        "print(dbscan_float.labels_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    1\n",
            "2    2\n",
            "dtype: int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlsyk9m9NN2K",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-extended"
      ]
    }
  ]
}