{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_config_info.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CeC-AbggYh6s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab configuration information\n",
        "This notebook is intended to simple dump status information on a Colab VM."
      ]
    },
    {
      "metadata": {
        "id": "m3SbviHli8Er",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Various installs used in this notebook\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "!pip install gputil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rim_Xy3h--W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CPU information"
      ]
    },
    {
      "metadata": {
        "id": "Cd9OM-gSYdaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# How many CPUs does this machine have?\n",
        "!lscpu | grep \"^CPU(s):\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z7eY-Lq9dFBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# More details on the CPU(s):\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhb8bXJIZU9t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RAM\n",
        "!cat /proc/meminfo | head -n3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LeSy0EpOigS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2215164-8450-45af-c16e-135e6b24233a"
      },
      "cell_type": "code",
      "source": [
        "# More RAM info\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAM Free: 12.8 GB  | Proc size: 249.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HeD7R1g_iFLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GPU information"
      ]
    },
    {
      "metadata": {
        "id": "V-Oo_YsDbYUi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What GPUs are available for use?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-tpXTLhbsg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What GPU is currently config'd for use?\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "# '' means none currently config'd for use\n",
        "\n",
        "\n",
        "# TODO: Another way?\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnpoONR1hBEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11aa678e-7c88-4997-ff45-e21310f50f03"
      },
      "cell_type": "code",
      "source": [
        "# Memory in GPU\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "\n",
        "import GPUtil as GPU\n",
        "\n",
        "gpus = GPU.getGPUs()\n",
        "\n",
        "if len(gpus) > 0:\n",
        "  gpu = gpus[0]\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "else:\n",
        "  print(\"No GPU config'd for use.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU config'd for use.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yc4jEhFyZDRi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Disk space\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DvI-zBE8dwud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reset VM\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5t8eFMPaJdc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "* [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "* [GPU stats code](https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available)\n"
      ]
    }
  ]
}